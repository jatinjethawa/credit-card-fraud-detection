{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"E:\\\\creditcard\\\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...         V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...   -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ...   -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...    0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ...   -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...   -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  Class  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 30 columns):\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(29), int64(1)\n",
      "memory usage: 65.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Explore the features available in your dataframe\n",
    "print(df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "0    0.998273\n",
      "1    0.001727\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of fraud and no fraud and print them\n",
    "occ = df['Class'].value_counts()\n",
    "print(occ)\n",
    "\n",
    "# Print the ratio of fraud cases\n",
    "print(occ / len(df.index))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Congratulations! As you can see, the ratio of fraudulent transactions is very low. This is a case of class imbalance problem, and you're going to learn how to deal with this in the next exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_tran=df.loc[df['Class']==0,'Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         149.62\n",
       "1           2.69\n",
       "2         378.66\n",
       "3         123.50\n",
       "4          69.99\n",
       "5           3.67\n",
       "6           4.99\n",
       "7          40.80\n",
       "8          93.20\n",
       "9           3.68\n",
       "10          7.80\n",
       "11          9.99\n",
       "12        121.50\n",
       "13         27.50\n",
       "14         58.80\n",
       "15         15.99\n",
       "16         12.99\n",
       "17          0.89\n",
       "18         46.80\n",
       "19          5.00\n",
       "20        231.71\n",
       "21         34.09\n",
       "22          2.28\n",
       "23         22.75\n",
       "24          0.89\n",
       "25         26.43\n",
       "26         41.88\n",
       "27         16.00\n",
       "28         33.00\n",
       "29         12.99\n",
       "           ...  \n",
       "284777      1.00\n",
       "284778     80.00\n",
       "284779     25.00\n",
       "284780     30.00\n",
       "284781     13.00\n",
       "284782     12.82\n",
       "284783     11.46\n",
       "284784     40.00\n",
       "284785      1.79\n",
       "284786      8.95\n",
       "284787      9.99\n",
       "284788      3.99\n",
       "284789     60.50\n",
       "284790      9.81\n",
       "284791     20.32\n",
       "284792      3.99\n",
       "284793      4.99\n",
       "284794      0.89\n",
       "284795      9.87\n",
       "284796     60.00\n",
       "284797      5.49\n",
       "284798     24.05\n",
       "284799     79.99\n",
       "284800      2.68\n",
       "284801      2.69\n",
       "284802      0.77\n",
       "284803     24.79\n",
       "284804     67.88\n",
       "284805     10.00\n",
       "284806    217.00\n",
       "Name: Amount, Length: 284315, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['Class'],axis=1)\n",
    "y=df.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = RandomOverSampler()\n",
    "X_resampled, y_resampled = method.fit_sample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568630"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568630"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_resampled)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Which resampling method to use?\n",
    "Random Under Sampling (RUS): throw away data, computationally efficient\n",
    "Random Over Sampling (ROS): straightforward and simple, but training your model on many duplicates\n",
    "Synthetic Minority Oversampling Technique (SMOTE): more sophisticated and realistic dataset, but you are training on \"fake\" data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When to use resampling methods\n",
    "Use resampling methods on your training set, never on your test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# Define resampling method and split into train and test\n",
    "method = SMOTE(kind='borderline1',ratio='minority')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    " train_size=0.8, random_state=0)\n",
    "# Apply resampling to the training data only\n",
    "X_resampled, y_resampled = method.fit_sample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     56861\n",
      "           1       0.21      0.89      0.34       101\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     56962\n",
      "   macro avg       0.60      0.94      0.67     56962\n",
      "weighted avg       1.00      0.99      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import  LogisticRegression\n",
    "# Continue fitting the model and obtain predictions\n",
    "model = LogisticRegression()\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Get your performance metrics\n",
    "predicted = model.predict(X_test)\n",
    "print (classification_report(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56518   343]\n",
      " [   11    90]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# traditionally fraud analyst use rule based system to detect frauds"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1]for example in case of credit cards analyst may create rule based on locations and block transactions from risky zipcodes.\n",
    "2]They might also create rules for cards used too frequently,for example in the last 30 minutes.\n",
    "3]Some of the rules are highly efficient at catching this frauds and some are not and rsult in false alarm too often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawbacks of using rules based systems\n",
    "Rules based systems have their limitations:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1]Threshold per rule are fixed to detect frauds and do not adapt according to fraudulant behavior changes over time.\n",
    "2]Limited to yes/no outcomes\n",
    "3]Fail to capture interaction between features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why use machine learning for fraud detection?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Machine learning models adapt to the data, and thus can change over time\n",
    "Uses all the data combined rather than a threshold per feature\n",
    "Can give a score, rather than a yes/no\n",
    "Will typically have a better performance and can be combined with rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the traditional way to catch fraud\n",
    "In this exercise you're going to try finding fraud cases in our credit card dataset the \"old way\". First you'll define threshold values using common statistics, to split fraud and non-fraud. Then, use those thresholds on your features to detect fraud. This is common practice within fraud analytics teams.\n",
    "\n",
    "Statistical thresholds are often determined by looking at the mean values of observations. Let's start this exercise by checking whether feature means differ between fraud and non-fraud cases. Then, you'll use that information to create common sense thresholds. Finally, you'll check how well this performs in fraud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008258</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>-0.007860</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>88.291022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.771948</td>\n",
       "      <td>3.623778</td>\n",
       "      <td>-7.033281</td>\n",
       "      <td>4.542029</td>\n",
       "      <td>-3.151225</td>\n",
       "      <td>-1.397737</td>\n",
       "      <td>-5.568731</td>\n",
       "      <td>0.570636</td>\n",
       "      <td>-2.581123</td>\n",
       "      <td>-5.676883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372319</td>\n",
       "      <td>0.713588</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.105130</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.051648</td>\n",
       "      <td>0.170575</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>122.211321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "Class                                                                         \n",
       "0      0.008258 -0.006271  0.012171 -0.007860  0.005453  0.002419  0.009637   \n",
       "1     -4.771948  3.623778 -7.033281  4.542029 -3.151225 -1.397737 -5.568731   \n",
       "\n",
       "             V8        V9       V10     ...           V20       V21       V22  \\\n",
       "Class                                   ...                                     \n",
       "0     -0.000987  0.004467  0.009824     ...     -0.000644 -0.001235 -0.000024   \n",
       "1      0.570636 -2.581123 -5.676883     ...      0.372319  0.713588  0.014049   \n",
       "\n",
       "            V23       V24       V25       V26       V27       V28      Amount  \n",
       "Class                                                                          \n",
       "0      0.000070  0.000182 -0.000072 -0.000089 -0.000295 -0.000131   88.291022  \n",
       "1     -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667  122.211321  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a groupby command on our labels and obtain the mean for each feature\n",
    "df.groupby('Class').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a rule for stating which cases are flagged as fraud\n",
    "\n",
    "df['flag_as_fraud']=np.where(np.logical_and(df['V1'] < -3,df['V3'] < -5),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged Fraud       0     1\n",
      "Actual Fraud               \n",
      "0              283089  1226\n",
      "1                 322   170\n"
     ]
    }
   ],
   "source": [
    "# Create a crosstab of flagged fraud cases versus the actual fraud cases\n",
    "print(pd.crosstab(df.Class, df.flag_as_fraud, rownames=['Actual Fraud'], colnames=['Flagged Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression combined with SMOTE\n",
    "In this exercise, you're going to take the Logistic Regression model from the previous exercise, and combine that with a SMOTE resampling method. We'll show you how to do that efficiently by using a pipeline that combines the resampling method with the model in one go. First, you need to define the pipeline that you're going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the pipeline module we need for this from imblearn\n",
    "from imblearn.pipeline import Pipeline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which resampling method and which ML model to use in the pipeline\n",
    "resampling = SMOTE(kind='borderline2')\n",
    "model = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline, tell it to combine SMOTE with the Logistic Regression model\n",
    "pipeline = Pipeline([('SMOTE', resampling), ('Logistic Regression', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data X and y, into a training and a test set and fit the pipeline onto the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fit your pipeline onto your training set and obtain predictions by fitting the model onto the test data \n",
    "pipeline.fit(X_train, y_train) \n",
    "predicted = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     85296\n",
      "           1       0.16      0.86      0.28       147\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     85443\n",
      "   macro avg       0.58      0.92      0.64     85443\n",
      "weighted avg       1.00      0.99      0.99     85443\n",
      "\n",
      "Confusion matrix:\n",
      " [[84657   639]\n",
      " [   21   126]]\n"
     ]
    }
   ],
   "source": [
    "# Obtain the results from the classification report and confusion matrix \n",
    "print('Classifcation report:\\n', classification_report(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural hit rate\n",
    "In this exercise, you'll again use credit card transaction data. The features and labels are similar to the data in the previous chapter, and the data is heavily imbalanced. We've given you features X and labels y to work with already, which are both numpy arrays.\n",
    "\n",
    "First you need to explore how prevalent fraud is in the dataset, to understand what the \"natural accuracy\" is, if we were to predict everything as non-fraud. It's is important to understand which level of \"accuracy\" you need to \"beat\" in order to get a better prediction than by doing nothing. In the following exercises, you'll create our first random forest classifier for fraud detection. That will serve as the \"baseline\" model that you're going to try to improve in the upcoming exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of observations from the length of y\n",
    "total_obs = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of non-fraudulent observations \n",
    "non_fraud = [i for i in y if i == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284315"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_non_fraud = non_fraud.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of non fraud observations in the dataset\n",
    "percentage = (float(count_non_fraud)/float(total_obs)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.82725143693798\n"
     ]
    }
   ],
   "source": [
    "# Print the percentage: this is our \"natural accuracy\" by doing nothing\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Good work! This tells us that by doing nothing, we would be correct in 99.82% of the cases. So now you understand, that if we get an accuracy of less than this number, our model does not actually add any value in predicting how many cases are correct. Let's see how a random forest does in predicting fraud in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier - part 1\n",
    "Let's now create a first random forest classifier for fraud detection. Hopefully you can do better than the baseline accuracy you've just calculated, which was roughly 99%. This model will serve as the \"baseline\" model that you're going to try to improve in the upcoming exercises. Let's start first with splitting the data into a test and training set, and defining the Random Forest model. The data available are features X and labels y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the random forest model from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split your data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Define the model as the random forest\n",
    "model = RandomForestClassifier(random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to our training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain predictions from the test data \n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994382219725431\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Print the accuracy performance metric\n",
    "print(accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Correct: Random Forest prevents overfitting most of the time, by creating random subsets of the features and building smaller trees using these subsets. Afterwards, it combines the subtrees of subsamples of features, so it does not tend to overfit to your entire feature set the way \"deep\" Decisions Trees do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance metrics for the RF model\n",
    "In the previous exercises you obtained an accuracy score for your random forest model. This time, we know accuracy can be misleading in the case of fraud detection. With highly imbalanced fraud data, the AUROC curve is a more reliable performance metric, used to compare different classifiers. Moreover, the classification report tells you about the precision and recall of your model, whilst the confusion matrix actually shows how many fraud cases you can predict correctly. So let's get these performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages to get the different performance metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Obtain the predictions from our random forest model \n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9316703210077877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.95      0.71      0.81       147\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     85443\n",
      "   macro avg       0.98      0.85      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "[[85291     5]\n",
      " [   43   104]]\n"
     ]
    }
   ],
   "source": [
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Precision Recall Curve\n",
    "You can also plot a Precision-Recall curve, to investigate the trade-off between the two in your model. In this curve Precision and Recall are inversely related; as Precision increases, Recall falls and vice-versa. A balance between these two needs to be achieved in your model, otherwise you might end up with many false positives, or not enough actual fraud cases caught. To achieve this and to compare performance, the precision-recall curves come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score,precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average precision and the PR curve\n",
    "average_precision = average_precision_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain precision and recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_pr_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-26a6f4f1e898>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plot the recall precision tradeoff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_pr_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_precision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_pr_curve' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot the recall precision tradeoff\n",
    "plot_pr_curve(recall, precision, average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'2-class Precision-Recall curve: AP=0.68')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf86170d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What's the benefit of the performance metric ROC curve (AUROC) versus Precision and Recall?\n",
    "\n",
    "\n",
    "The AUROC answers the question: \"How well can this classifier be expected to perform in general, at a variety of different baseline probabilities?\" but precision and recall don't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct: The ROC curve plots the true positives vs. false positives , for a classifier, as its discrimination threshold is varied. Since, a random method describes a horizontal curve through the unit interval, it has an AUC of 0.5. Minimally, classifiers should perform better than this, and the extent to which they score higher than one another (meaning the area under the ROC curve is larger), they have better expected performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model adjustments\n",
    "A simple way to adjust the random forest model to deal with highly imbalanced fraud data, is to use the class_weights option when defining your sklearn model. However, as you will see, it is a bit of a blunt force mechanism and might not work for your very special case.\n",
    "\n",
    "In this exercise you'll explore the weight = \"balanced_subsample\" mode the Random Forest model from the earlier exercise. You already have split your data in a training and test set, i.e X_train, X_test, y_train, y_test are available. The metrics function have already been imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9283248682140274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.94      0.73      0.82       147\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     85443\n",
      "   macro avg       0.97      0.86      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "[[85289     7]\n",
      " [   40   107]]\n"
     ]
    }
   ],
   "source": [
    "# Define the model with balanced subsample\n",
    "model = RandomForestClassifier(class_weight='balanced_subsample', random_state=5)\n",
    "\n",
    "# Fit your training model to your training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the predicted values and probabilities from the model \n",
    "predicted = model.predict(X_test)\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# Print the roc_auc_score, the classification report and confusion matrix\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You can see that the model results don't improve drastically. We now have 3 less false positives, but now 19 in stead of 18 false negatives, i.e. cases of fraud we are not catching. If we mostly care about catching fraud, and not so much about the false positives, this does actually not improve our model at all, albeit a simple option to try. In the next exercises you'll see how to more smartly tweak your model to focus on reducing false negatives and catch more fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this exercise you're going to tweak our model in a less \"random\" way, but use GridSearchCV to do the work for you.\n",
    "\n",
    "With GridSearchCV you can define which performance metric to score the options on. Since for fraud detection we are mostly interested in catching as many fraud cases as possible, you can optimize your model settings to get the best possible Recall score. If you also cared about reducing the number of false positives, you could optimize on F1-score, this gives you that nice Precision-Recall trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter sets to test\n",
    "param_grid = {'n_estimators': [1, 30], 'max_features': ['auto', 'log2'], 'max_depth' : [4, 8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  GridSearchCV\n",
    "\n",
    "# Define the model to use\n",
    "model = RandomForestClassifier(random_state=5)\n",
    "\n",
    "# Combine the parameter sets with the defined model\n",
    "grid_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='recall', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\lib\\site-packages\\sklearn\\externals\\joblib\\disk.py:122: UserWarning: Unable to delete folder C:\\Users\\DELL\\AppData\\Local\\Temp\\joblib_memmapping_folder_9868_5231651083 after 5 tentatives.\n",
      "  .format(folder_path, RM_SUBDIRS_N_RETRY))\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\DELL\\\\AppData\\\\Local\\\\Temp\\\\joblib_memmapping_folder_9868_5231651083\\\\9868-1990819998576-90dcd08243264e0ea82491956a097e1a.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-d04865fe28ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the model to our training data and obtain best parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgrid_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_terminate_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;31m# in latter calls but we free as much memory as we can by deleting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[1;31m# the shared memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdelete_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\sklearn\\externals\\joblib\\disk.py\u001b[0m in \u001b[0;36mdelete_folder\u001b[1;34m(folder_path, onerror)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWindowsError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;31m# Allow introspection of whether or not the hardening against symlink\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    387\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\DELL\\\\AppData\\\\Local\\\\Temp\\\\joblib_memmapping_folder_9868_5231651083\\\\9868-1990819998576-90dcd08243264e0ea82491956a097e1a.pkl'"
     ]
    }
   ],
   "source": [
    "# Fit the model to our training data and obtain best parameters\n",
    "grid_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-ceba24fd1499>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCV_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "CV_model.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Great job! You've managed to improve your model even further. The number of false positives has now been slightly reduced even further, which means we are catching more cases of fraud. However, you see that the number of false positives actually went up. That is that Precision-Recall trade-off in action. To decide which final model is best, you need to take into account how bad it is not to catch fraudsters, versus how many false positives the fraud analytics team can deal with. Ultimately, this final decision should be made by you and the fraud team together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-84-2fe988604291>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-84-2fe988604291>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    ensemble_model = VotingClassifier(estimators=[('lr', clf1),\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "ensemble_model = VotingClassifier(estimators=[('lr', clf1),\n",
    "('rf', clf2), ('gnb', clf3)], voting='hard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model.fit(X_train, y_train)\n",
    "ensemble_model.predict(X_test)\n",
    " VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), \n",
    "('gnb', clf3)], voting='soft', weights=[2,1,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
